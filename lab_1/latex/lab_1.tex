\documentclass[a4paper, 12pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{cmap}
\usepackage[english, russian]{babel}
\usepackage{indentfirst}
\usepackage[left=20mm, top=20mm, right=20mm, bottom=20mm]{geometry}
\usepackage{tikz}
\usepackage{float}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{graphicx}
\usepackage{fancybox, fancyhdr}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Лабораторная работа №1}
\fancyhead[R]{Математическая статистика}
\fancyfoot[C]{\thepage}
\graphicspath{{images/}}
\usetikzlibrary{patterns}
\definecolor{LightGray}{gray}{0.95}
\definecolor{LightGray2}{gray}{0.7}
\lstdefinestyle{code}{
    language=Python, % replace with needed language
    basicstyle=\footnotesize\ttfamily,
    backgroundcolor=\color{LightGray},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    frame=single,
    rulecolor=\color{LightGray2},
    linewidth=\linewidth,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!40!black},
    stringstyle=\color{purple},
    escapeinside={\%*}{*)},
    inputencoding=utf8x,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    framexrightmargin=0pt
}
\lstset{style=code}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={contents setup},
    pdfpagemode=FullScreen,
}
\setlength{\parskip}{1.5mm}
\setlength{\headheight}{15pt}
\setlength{\footskip}{15pt}
\allowdisplaybreaks
\DeclareMathOperator{\sinc}{sinc}
\newcommand{\frc}[2]{\raisebox{2pt}{$#1$}\big/\raisebox{-3pt}{$#2$}}

\begin{document}
    \begin{titlepage}

        \begin{center}
        \includegraphics[width=0.3\textwidth]{itmo.png} % requires itmo.png in /images folder
        \vfill
        
        Федеральное государственное автономное образовательное учреждение высшего образования
        «Национальный Исследовательский Университет ИТМО»\\
        
        \vfill
        {\large\bf ЛАБОРАТОРНАЯ РАБОТА №1}\\
        {\large\bf ПРЕДМЕТ «МАТЕМАТИЧЕСКАЯ СТАТИСТИКА»}\\
        Вариант 4, 2
        \vfill

        \begin{flushright}
            \begin{minipage}{.45\textwidth}
            {
                \hbox{Преподаватель: Лимар И. А.}
                \hbox{Студент: Румянцев А. А.}
                \hbox{Поток: Мат Стат 31.2}
                \hbox{}
                \hbox{Факультет: СУиР}
                \hbox{Группа: R3341}
            }
            \end{minipage}
        \end{flushright}
        
        \vfill
                
        Санкт-Петербург\\
        2024
        \end{center}
    \end{titlepage}
    
    \tableofcontents

    \newpage
    \section{Задание 1}
    \subsection{Условие}
    В файле mobile\_{phones}.csv приведены данные о мобильных телефонах. В сколько моделей
    можно вставить 2 сим-карты, сколько поддерживают 3-G, каково наибольшее число ядер
    у процессора? Рассчитайте выборочное среднее, выборочную дисперсию, выборочную медиану
    и выборочную квантиль порядка 2/5, построить график эмпирической функции
    распределения, гистограмму и box-plot для емкости аккумулятора для всей совокупности
    и в отдельности для поддерживающих/не поддерживающих Wi-Fi


    \subsection{Выполнение}
    Для начала импортируем необходимые библиотеки
    \begin{lstlisting}[label=import, caption={Импортирование библиотек}]
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    \end{lstlisting}


    Теперь считаем таблицу по ссылке на представленный гугл-диск в переменную df
    \begin{lstlisting}[label=read, caption={Считывание таблицы}]
    url='https://drive.google.com/file/d/1O4rFr9xg9aFmkjx4-hl_XOc5O9q65_EW\
        /view?usp=sharing'
    url='https://drive.google.com/uc?id=' + url.split('/')[-2]
    df = pd.read_csv(url)
    \end{lstlisting}


    В колонках <<dual\_{sim}>> и <<three\_{g}>> наличие или отсутствие параметра определяется
    единицей или нулем соответственно, следовательно, просуммировав значения в этих столбцах,
    получим количество моделей с наличием данных параметров. Для ядер просто выведем максимум
    из столбца. Используем методы библиотеки \texttt{pandas} -- \texttt{sum} и \texttt{max}
    \begin{lstlisting}[label=3q, caption={Код на ответы на первые три вопроса}]
    # how many models can you insert 2 SIM cards into?
    dual_sim_count = df['dual_sim'].sum()
    print(f'dual_sim_count={dual_sim_count}')
        
    # how many models support 3-G?
    three_g_count = df['three_g'].sum()
    print(f'three_g_count={three_g_count}')
        
    # what is the highest number of cores a processor has?
    max_cores = df['n_cores'].max()
    print(f'max_cores={max_cores}')
    \end{lstlisting}

    
    Получим следующий вывод в консоль
    \begin{lstlisting}[label=3qa, caption={Вывод в консоль: ответы на первые три вопроса}]
    dual_sim_count=1019
    three_g_count=1523
    max_cores=8
    \end{lstlisting}


    Для расчета необходимых характеристик я написал отдельный метод, куда достаточно
    передать выборку и ее именование для удобного вывода в консоль. Используем методы
    библиотеки \texttt{pandas} -- \texttt{mean} посчитает выборочное среднее,
    \texttt{var} выборочную дисперсию, \texttt{median} выборочную медиану и \texttt{quantile}
    с параметром \texttt{q=2/5} квантиль порядка 2/5
    \begin{lstlisting}[label=mvals, caption={Код для подсчета основных характеристик}]
    # calculating the main values
    def calculate_print_values(df: pd.Series, name: str):
        mean = df.mean()
        print(f'mean_{name}={mean}')
        
        var = df.var()
        print(f'var_{name}={var}')
        
        median = df.median()
        print(f'median_{name}={median}')
        
        quantile_2d5 = df.quantile(q=2/5)
        print(f'quantile_2/5_{name}={quantile_2d5}')
    \end{lstlisting}


    Зададим сразу три выборки -- всю, только модели с наличием Wi-Fi и только с отсутствием.
    Для составления выборок с конкретным значением требуемого параметра берем нужный столбец
    и составляем построчную связку индекс-булеан, где значением будет являться результат проверки заданного условия.
    Обращаемся к исходной таблице по этой связке и получаем новую таблицу только с теми строками, для которых по индексу
    значение было равным \texttt{True}, то есть условие выполнилось. Далее от полученной таблицы отбираем столбец по условию задания.
    Для удобного вывода добавим метод разделитель, который будем вызывать между операциями с выборками.
    Вызовем подсчитывающий метод три раза для трех выборок
    \begin{lstlisting}[label=mvals2, caption={Подготовка для удобного и быстрого получения результатов}]
    # common separator between unrelated outputs
    def print_separate():
        print('----------------')

    # the entire sample
    all_battery = df['battery_power']
    calculate_print_values(all_battery, name='all_battery')

    print_separate()

    # selection with the condition of wifi availability
    wifi_table = df[df['wifi']==1]
    wifi_battery = wifi_table['battery_power']
    calculate_print_values(wifi_battery, name='wifi_battery')

    print_separate()

    # selection with the condition of wifi unavailability
    nowifi_table = df[df['wifi']==0]
    no_wifi_battery = nowifi_table['battery_power']
    calculate_print_values(no_wifi_battery, name='no_wifi_battery')
    \end{lstlisting}


    С заданными ранее параметрами получаем следующий вывод в консоль
    \begin{lstlisting}[label=mvalsout, caption={Вывод в консоль: посчитанные основные характеристики}]
    mean_all_battery=1238.5185
    var_all_battery=193088.35983766883  
    median_all_battery=1226.0
    quantile_2/5_all_battery=1076.0     
    ----------------
    mean_wifi_battery=1234.9043392504932
    var_wifi_battery=190296.40051422242 
    median_wifi_battery=1233.0
    quantile_2/5_wifi_battery=1077.8000000000002
    ----------------
    mean_no_wifi_battery=1242.235294117647      
    var_no_wifi_battery=196128.43798148702      
    median_no_wifi_battery=1222.0
    quantile_2/5_no_wifi_battery=1076.0
    \end{lstlisting}


    Теперь построим графики в соответствии с заданием.
    Напишем метод, который принимает выборку и название графика -- таким образом, достаточно
    будет вызвать метод для каждой выборки и получить все графики. Используем библиотеку 
    \texttt{matplotlib} для отрисовки, \texttt{pandas} для подсчета необходимых данных.
    Для построения графика эмпирической функции распределения находим
    по сортированным данным без сохранения индексов связку ключ-значение, где ключ --
    \texttt{battery\_{power}}, значение -- вероятность встретить именно такую \texttt{battery\_{power}}.
    После составляем кумулятивные суммы по этим вероятностям. Для гистограммы определяем
    количество интервалов правилом Стёрджеса: $n=1+\log_2{N}$ и округляем вниз
    \begin{lstlisting}[label=graps, caption={Код для построения необходимых графиков}]
    # plotting basic graphs
    def show_graphs(df: pd.Series, name='sample'):
        # the resulting axis will be labeled 0, 1, ..., n - 1
        sorted_ = df.sort_values(ignore_index=True)

        # normalize for proportions (probabilities) instead of freqs
        # sorting by DataFrame column values (not by freqs)
        idx_prob = sorted_.value_counts(normalize=True, sort=False)

        # parsing x & y then cumsum for distribution function
        plt.plot(idx_prob.index, idx_prob.values.cumsum())
        plt.title(f'Empirical distribution function of {name}')
        plt.xlabel('battery_power')
        plt.ylabel('probability')
        plt.grid()
        plt.gcf().set_size_inches(10, 5)
        plt.show()

        # Sturges' rule
        n = np.int64(np.floor(1+3.322*np.log10(df.shape[0])))
        plt.hist(df, bins=n)
        plt.title(f'Histogram of {name}')
        plt.xlabel('battery_power')
        plt.ylabel('count')
        plt.grid()
        plt.gcf().set_size_inches(10, 5)
        plt.show()

        plt.boxplot(df)
        plt.title(f'Boxplot of {name}')
        plt.ylabel('battery_power')
        plt.grid()
        plt.gcf().set_size_inches(10, 5)
        plt.show()
    \end{lstlisting}


    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{all_battery_edf.png}
        \captionsetup{skip=0pt}
        \caption{График эмпирической функции распределения для всей выборки}
        \label{fig:allbedf}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{all_battery_hist.png}
        \captionsetup{skip=0pt}
        \caption{Гистограмма для всей выборки}
        \label{fig:allbhist}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{all_battery_box.png}
        \captionsetup{skip=0pt}
        \caption{Ящик с усами для всей выборки}
        \label{fig:allbbox}
    \end{figure}


    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{wifi_battery_edf.png}
        \captionsetup{skip=0pt}
        \caption{График эмпирической функции распределения для выборки моделей с Wi-Fi}
        \label{fig:wifibedf}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{wifi_battery_hist.png}
        \captionsetup{skip=0pt}
        \caption{Гистограмма для выборки моделей с Wi-Fi}
        \label{fig:wifibhist}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{wifi_battery_box.png}
        \captionsetup{skip=0pt}
        \caption{Ящик с усами для выборки моделей с Wi-Fi}
        \label{fig:wifibbox}
    \end{figure}


    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{no_wifi_battery_edf.png}
        \captionsetup{skip=0pt}
        \caption{График эмпирической функции распределения для выборки моделей без Wi-Fi}
        \label{fig:nowifibedf}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{no_wifi_battery_hist.png}
        \captionsetup{skip=0pt}
        \caption{Гистограмма для выборки моделей без Wi-Fi}
        \label{fig:nowifibhist}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{no_wifi_battery_box.png}
        \captionsetup{skip=0pt}
        \caption{Ящик с усами для выборки моделей без Wi-Fi}
        \label{fig:nowifibbox}
    \end{figure}


    \newpage
    Исходя из результирующих графиков можно сделать вывод, что мы верно посчитали характеристики,
    представленные в листинге \ref{mvalsout}.
    На рис. \ref{fig:allbedf} вероятность всегда неубывает, медиана прослеживается
    в районе значения, посчитанного ранее. На рис. \ref{fig:allbhist} столбцы примерно одинаковой высоты --
    распределение скорее всего равномерное. На рис. \ref{fig:allbbox} медиана отмечена
    оранжвой прямой, находится примерно в центре ящика -- распределение данных относительно
    симметрично, и, ее значение совпадает с вычисленным. Интервал между минимумом и максимумом значений в ящике получился
    широким, что подтверждает большое значение вычисленной ранее дисперсии. Выбросы отсутствуют (нет точек вне усов).
    Рассуждения аналогичны для графиков с другой выборкой.


    \section{Задание 2}
    \subsection{Условие}
    Методом моментов найти оценку квадрата масштабирующего параметра $\theta$ распределения Лапласа
    (сдвиг считать нулевым). Эксперимент при $\theta=0.5$. \textbf{Указание}: для плотности используйте
    параметризацию $$f_{\theta}(x)=\dfrac{1}{2\theta}\exp{\left\{-\dfrac{|x|}{\theta}\right\}}$$


    Найти смещение, дисперсию, среднеквадратическую ошибку (\textbf{теоретические}) и указать свойства оценок.
    Также провести эксперимент при указанных параметрах по следующей схеме:
    \begin{enumerate}
        \item Задайте массив объемов выборки
        \item Для каждого объема выборки $n$ сгенерируйте $m$ выборок из вашего распределения и для каждой
        сгенерированной выборки посчитайте оценку параметра согласно полученной формуле
        \item Обработайте результаты (посчитайте выборочные характеристики для разницы между оценкой и реальным
        параметром для каждого объема выборки, количество выборок, для которых оценка отличается от реального
        параметра более чем на заданный вами порог и т. п.), визуализируйте результат
    \end{enumerate}


    \subsection{Выполнение}
    Чтобы найти $\hat{\theta}^2$ методом моментов, необходимо приравнять теоретический и эмпирический
    моменты порядка $k$. Теоретический выражается как функция от параметров распределения, которые мы
    оцениваем. Эмпирический определяется на основе данных выборки.


    Для начала определимся с тем, сколько нужно задать функций $g_i(x)$, по которым мы будем искать оценки $\hat{\theta_i}$
    параметров распределения -- нам известен сдвиг $\mu=0$ и нужно оценить только $\theta^2$, следовательно количество
    неизвестных $d=1$, а значит нам нужно задать одну функцию $g(x)$ и по ней найти одну оценку $\hat{\theta}^2$.


    Начнем с нахождения теоретического момента. Нам необходимо задать такую функцию $$g(x)=x^k,$$ которая
    при поиске $k$-го момента позволит нам получить выражение с $\theta^2$, чтобы после приравнивания моментов
    мы могли выразить оценку $\hat{\theta}^2$ этого параметра.


    Попробуем задать $g(x)=x$. В таком случае, согласно википедии, получим первый момент
    (математическое ожидание) для распределения Лапласа, равный(-ое)
    сдвигу $\mu$, который в нашем случае отсутствует
    $$\mathbb{E}\left[g(x)\right]=\mathbb{E}\left[x\right]=\mu=0$$
    С первым моментом выражения с $\theta^2$ не получилось. Тогда, пусть $g(x)=x^2$ -- теперь
    найдем второй момент для распределения Лапласа. Пользуясь википедией, получим
    $$\mathbb{E}\left[g(x)\right]=\mathbb{E}\left[x^2\right]=\int\limits_{-\infty}^{\infty}x^2f(x)\,dx=\mu^2+2\theta^2=/\mu=0/=2\theta^2$$
    Мы получили теоретический момент порядка $k=2$ для распределения Лапласа.
    
    
    Найдем эмпирический момент порядка $k=2$ для распределения Лапласа. Имеем на данный момент такое выражение
    $$\mathbb{E}\left[g(x)\right]=\mathbb{E}\left[x^2\right]=2\theta^2$$
    Запишем вместо математического ожидания $\mathbb{E}\left[x^2\right]$ выборочный аналог таким способом
    $$\mathbb{E}\left[g_i(x_j)\right]=\dfrac{1}{n}\sum\limits_{j=1}^{n}g_i(x_j)\Rightarrow \mathbb{E}\left[g(x_j)\right]=\mathbb{E}\left[x_j^2\right]=\dfrac{1}{n}\sum\limits_{j=1}^{n}x_j^2$$
    Полученное для $\mathbb{E}\left[x_j^2\right]$ выражение является эмпирическим вторым моментом для распределения Лапласа.


    Приравняем эмпирический и теоретический моменты второго порядка и выразим оценку квадрата параметра $\theta$
    $$\dfrac{1}{n}\sum\limits_{j=1}^{n}x_j^2=2\theta^2\Rightarrow\hat{\theta}^2=\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_j^2$$


    Таким образом, методом моментов оценка квадрата масштабирующего параметра $\theta$ распределения Лапласа имеет вид
    $$\hat{\theta}^2=\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_j^2$$
    Далее будем находить характеристики и проводить эксперименты с данным в условии значением $\theta=0.5$.


    Смещение можно найти по следующей формуле $$\text{bias}{\left[\hat{\theta},\,\theta\right]}=\mathbb{E}\left[\hat{\theta}\right]-\theta$$
    Если результат выражения выше равен нулю, значит оценка является несмещенной. В нашем случае имеем
    $$\text{bias}{\left[\hat{\theta}^2,\,\theta^2\right]}=\mathbb{E}\left[\hat{\theta}^2\right]-\theta^2$$
    Вычислим это выражение, применяя свойства математического ожидания. $\theta^2$ является
    константой и мы сразу можем ее вычислить. Рассмотрим подробнее $\mathbb{E}\left[\hat{\theta}^2\right]$
    $$\mathbb{E}\left[\hat{\theta}^2\right]=\mathbb{E}\left[\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_j^2\right]=\dfrac{1}{2n}\mathbb{E}\left[\sum\limits_{j=1}^{n}x_j^2\right]
    =\dfrac{1}{2n}\sum\limits_{j=1}^{n}\mathbb{E}\left[x_j^2\right],$$
    $$\sum\limits_{j=1}^{n}\mathbb{E}\left[x_j^2\right]=
    \begin{bmatrix}
        \mathbb{E}\left[x^2\right]=2\theta^2\\
        \mathbb{E}\left[x_1^2\right]=2\theta^2\\
        \vdots \\
        \mathbb{E}\left[x_n^2\right]=2\theta^2
    \end{bmatrix}=
    n\cdot2\theta^2,
    $$
    $$\dfrac{1}{2n}\sum\limits_{j=1}^{n}\mathbb{E}\left[x_j^2\right]=\dfrac{1}{2n}\cdot n\cdot2\theta^2=\theta^2
    \Rightarrow \mathbb{E}\left[\hat{\theta}^2\right]=\theta^2$$
    Теперь вычислим смещение
    $$\text{bias}{\left[\hat{\theta}^2,\,\theta^2\right]}=\mathbb{E}\left[\hat{\theta}^2\right]-\theta^2=\theta^2-\theta^2=0$$
    Таким образом, оценка является несмещенной.


    Вычислим теоретическую дисперсию оценки, пользуясь свойствами дисперсии и математического ожидания. В ходе вычислений вспомним биномиальный коэффициент и гамма функцию
    $$\text{Var}{\left[\hat{\theta}^2\right]}=\mathbb{E}\left[\hat{\theta}^4\right]-\left(\mathbb{E}\left[\hat{\theta}^2\right]\right)^2
    =\begin{bmatrix}
        \mathbb{E}\left[\hat{\theta}^2\right]=\theta^2\\
        \mathbb{E}\left[\hat{\theta}^4\right]=\mathbb{E}\left[\left(\hat{\theta}^2\right)^2\right]
    \end{bmatrix}
    =\mathbb{E}\left[\left(\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_j^2\right)^2\right]-\left(\theta^2\right)^2,$$
    $$\mathbb{E}\left[\left(\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_j^2\right)^2\right]=\dfrac{1}{4n^2}\mathbb{E}\left[\left(\sum\limits_{j=1}^{n}x_j^2\right)^2\right],$$
    $$\left(\sum\limits_{j=1}^{n}x_j^2\right)^2=\sum\limits_{j=1}^{n}x_j^4+2\sum\limits_{i\neq j}x_i^2x_j^2\Rightarrow \mathbb{E}\left[\hat{\theta}^4\right]=\dfrac{1}{4n^2}\mathbb{E}\left[\sum\limits_{j=1}^{n}x_j^4+2\sum\limits_{i\neq j}x_i^2x_j^2\right],$$
    $$\mathbb{E}\left[\sum\limits_{j=1}^{n}x_j^4+2\sum\limits_{i\neq j}x_i^2x_j^2\right]=\mathbb{E}\left[\sum\limits_{j=1}^{n}x_j^4\right]+\mathbb{E}\left[2\sum\limits_{i\neq{j}}x_i^2x_j^2\right]=
    \sum\limits_{j=1}^{n}E\left[x_j^4\right]+2\sum\limits_{i\neq{j}}\mathbb{E}\left[x_i^2x_j^2\right],$$
    $$\sum\limits_{i\neq{j}}\mathbb{E}\left[x_i^2x_j^2\right]=/\text{случ. вел. }x_i \text{ независимы}/=\sum\limits_{i\neq{j}}\mathbb{E}\left[x_i^2\right]\mathbb{E}\left[x_j^2\right],$$
    $$2\sum\limits_{i\neq{j}}\mathbb{E}\left[x_i^2x_j^2\right]=2\sum\limits_{i\neq{j}}\mathbb{E}\left[x_i^2\right]\mathbb{E}\left[x_j^2\right]=/\mathbb{E}\left[x^2\right]=2\theta^2/=2\sum\limits_{i\neq{j}}2\theta^2\cdot2\theta^2=8\theta^4\sum\limits_{i\neq{j}}1,$$
    $$\sum\limits_{i\neq{j}}1=
    /\text{бином. коэфф.}/=
    \begin{pmatrix}
        n\\
        k=2>0
    \end{pmatrix}
    =\dfrac{n\left(n-1\right)}{2},$$
    $$2\sum\limits_{i\neq{j}}\mathbb{E}\left[x_i^2x_j^2\right]=8\theta^4\cdot\dfrac{n\left(n-1\right)}{2}=4\theta^4n\left(n-1\right),$$
    $$\sum\limits_{j=1}^{n}\mathbb{E}\left[x_j^4\right]=
    \begin{bmatrix}
        \mathbb{E}\left[x^4\right]=\alpha\\
        \mathbb{E}\left[x_1^4\right]=\alpha\\
        \vdots \\
        \mathbb{E}\left[x_n^4\right]=\alpha
    \end{bmatrix}=
    n\cdot\mathbb{E}\left[x^4\right],\text{ где }\mathbb{E}\left[x^4\right]\text{ -- четвертый момент},$$
    $$\mathbb{E}\left[x^4\right]=\int\limits_{-\infty}^{\infty}x^4f(x)\,dx=\int\limits_{-\infty}^{\infty}x^4\cdot\dfrac{1}{2\theta}\exp{\left\{-\dfrac{|x|}{\theta}\right\}}\,dx=\dfrac{1}{2\theta}\int\limits_{-\infty}^{\infty}x^4\exp{\left\{-\dfrac{|x|}{\theta}\right\}}\,dx$$
    Так как в нашем распределении Лапласа сдвиг отсутствует ($\mu=0$), то это означает, что распределение симметрично относительно нуля. Тогда, вычислим интеграл только для
    положительных значений $x$ и умножим его на два. При условии $x\geq0$ получаем $|x|=x$
    $$\mathbb{E}\left[x^4\right]=\dfrac{1}{2\theta}\int\limits_{-\infty}^{\infty}x^4\exp{\left\{-\dfrac{|x|}{\theta}\right\}}\,dx=2\cdot\dfrac{1}{2\theta}\int\limits_{0}^{\infty}x^4\exp{\left\{-\dfrac{x}{\theta}\right\}}\,dx=
    \dfrac{1}{\theta}\int\limits_{0}^{\infty}x^4\exp{\left\{-\dfrac{x}{\theta}\right\}}\,dx,$$
    $$\dfrac{1}{\theta}\int\limits_{0}^{\infty}x^4\exp{\left\{-\dfrac{x}{\theta}\right\}}\,dx=
    \begin{bmatrix}
        u=\dfrac{x}{\theta}\\
        du=\dfrac{dx}{\theta}
    \end{bmatrix}=
    \dfrac{1}{\theta}\int\limits_{0}^{\infty}u^4\theta^4e^{-u}\theta\,du=\theta^4\int\limits_{0}^{\infty}u^4e^{-u}\,du=\theta^4\cdot\Gamma{(z)},$$
    $$\Gamma{(z)}=\int\limits_{0}^{\infty}t^{z-1}e^{-t}\,dt\Rightarrow\int\limits_{0}^{\infty}u^4e^{-u}\,du=\Gamma{(z-1=4)}=\Gamma{(5)}=24\Rightarrow\mathbb{E}\left[x^4\right]=\theta^4\cdot\Gamma{(5)}=\theta^4\cdot24,$$
    $$\sum\limits_{j=1}^{n}\mathbb{E}\left[x_j^4\right]=n\cdot\mathbb{E}\left[x^4\right]=n\cdot\theta^4\cdot24,$$
    $$\mathbb{E}\left[\hat{\theta}^4\right]=\dfrac{1}{4n^2}\left(\sum\limits_{j=1}^{n}E\left[x_j^4\right]+2\sum\limits_{i\neq{j}}\mathbb{E}\left[x_i^2x_j^2\right]\right)=
    \dfrac{1}{4n^2}\left(24\theta^4n+4\theta^4n\left(n-1\right)\right),$$
    $$\dfrac{1}{4n^2}\left(24\theta^4n+4\theta^4n\left(n-1\right)\right)=\dfrac{4\theta^4n}{4n^2}\left(6+n-1\right)=\dfrac{\theta^4}{n}\left(n+5\right)=\theta^4\left(1+\dfrac{5}{n}\right)=\mathbb{E}\left[\hat{\theta}^4\right],$$
    $$\text{Var}{\left[\hat{\theta}^2\right]}=\mathbb{E}\left[\hat{\theta}^4\right]-\left(\mathbb{E}\left[\hat{\theta}^2\right]\right)^2=
    \theta^4\left(1+\dfrac{5}{n}\right)-\theta^4=\theta^4\left(1+\dfrac{5}{n}-1\right)=\dfrac{5\theta^4}{n}$$
    При условии, что эксперимент проводится для $\theta=0.5$, получим
    $$\text{Var}{\left[\hat{\theta}^2\right]}=\dfrac{5\cdot0.5^4}{n}=\dfrac{0.3125}{n}$$
    На самом деле, вследствие независимости случайных величин $x_i$ достаточно было вычислить выражение ниже, чтобы избежать лишних шагов, так как ковариации между независимыми случайными величинами равны нулю
    $$\text{Var}{\left[\hat{\theta}^2\right]}=\text{Var}{\left[\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_j^2\right]}=\dfrac{1}{4n^2}\left(\sum\limits_{j=1}^{n}\text{Var}\left[x_{j}^2\right]+2\sum\limits_{i\neq{j}}\text{Cov}\,\left[x_i^2,x_j^2\right]\right)=\dfrac{1}{4n^2}\sum\limits_{j=1}^{n}\text{Var}\left[x_{j}^2\right]$$

    
    Найдем теоретическую среднеквадратическую ошибку. Так как оценка является несмещенной, то теоретические среднеквадратическая ошибка и дисперсия равны. Таким образом, получим
    $$\text{MSE}{\left[\hat{\theta}^2\right]}=\text{Var}{\left[\hat{\theta}^2\right]}=\dfrac{0.3125}{n}$$


    Далее распишем свойства оценки. Мы уже знаем, что оценка является \textbf{несмещенной}, так как смещение $\text{bias}{\left[\hat{\theta}^2,\,\theta^2\right]}=0$ ($\mathbb{E}\left[\hat{\theta^2}\right]=\theta^2$), т. е. отсутствует.


    Проверим состоятельность оценки
    $$\lim\limits_{n\rightarrow\infty}\text{MSE}{\left[\hat{\theta}^2\right]}=\lim\limits_{n\rightarrow\infty}\text{Var}{\left[\hat{\theta}^2\right]}=\lim\limits_{n\rightarrow\infty}\dfrac{0.3125}{n}=\left\{\dfrac{0.3125}{\infty}\right\}=0,$$
    из чего следует, что оценка является \textbf{состоятельной}, так как чем больше данных, тем более точной становится оценка.


    Так как других оценок кроме полученной не имеется, не можем сравнить среднеквадратические ошибки оценок и на этой основе сделать вывод об эффективности -- \textbf{эффективность не гарантируется}.


    Проверим асимптотическую нормальность. Так как случайные величины
    \begin{enumerate}
        \item Независимы,
        \item Одинаково распределены (все случ. вел. $x_i$ имеют одно и то же распределение с одинаковыми мат. ожиданиями и дисперсией),
        \item Имеют конечные математическое ожидание и дисперсию,
    \end{enumerate}
    и, дисперсия среднего (то есть дисперсия квадрата оценки масштабирующего параметра $\theta$) с увеличенем объема выборки уменьшается,
    то, по центральной предельной теореме (ЦПТ) сумма (или среднее) этих случайных величин при $n\rightarrow\infty$ будет приближаться по распределению $d$ к нормальному распределению,
    то есть $$\sqrt{n}\left(\hat{\theta}-\theta\right)\xrightarrow{d}\mathcal{N}\left(0,\sigma^2\left[\theta\right]\right),$$ что в нашем случае будет иметь вид
    $$\sqrt{n}\left(\hat{\theta}^2-\theta^2\right)\xrightarrow{d}\mathcal{N}\left(0,\text{Var}{\left[\hat{\theta}^2\right]}\right),$$
    $$\sqrt{n}\left(\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_{j}^2-\theta^2\right)\xrightarrow{d}\mathcal{N}\left(0,\dfrac{5\theta^4}{n}\right),$$
    где $\dfrac{1}{2n}\sum\limits_{j=1}^{n}x_{j}^2$ -- среднее квадратичных отклонений. Следовательно, оценка является \textbf{асимптотически нормальной}.
\end{document}